# 算法设计与智能计算课程大作业

## 摘要（Abstract）

扩散模型（Diffusion Models）近年来在生成建模领域受到广泛关注，其通过正向逐步加噪与反向逐步去噪的随机过程，实现了从简单分布到复杂数据分布的稳定映射，在图像生成等任务中展现出良好的训练稳定性与生成质量。Denoising Diffusion Probabilistic Models（DDPM）作为扩散模型的代表方法，在理论推导与工程实现之间具有清晰对应关系，适合作为生成模型算法设计与复现的研究对象。

本项目以 **DDPM 原论文为核心研究对象，目标是在 PyTorch 框架下完成 DDPM 的算法级复现**。具体而言，项目系统学习并梳理了 DDPM 的数学原理，在此基础上从零实现了其前向扩散过程、反向去噪采样算法以及基于 U-Net 的噪声预测网络，未直接调用现成的 DDPM 算法库。进一步地，引入 OpenAI 提出的 Improved DDPM 作为拓展方法，对比分析算法改进对生成性能的影响。

实验在 CIFAR-10 数据集上进行。结果表明，所复现的 DDPM 算法能够稳定生成具有合理结构的图像，其生成效果与公开实现基本一致；对比实验显示，Improved DDPM 在生成质量与训练稳定性方面相较原始 DDPM 具有一定提升。综上，本项目验证了 DDPM 算法在 PyTorch 框架下的可复现性，并分析了改进方法带来的性能变化与实现代价，为进一步研究扩散模型提供了实践依据。



## 第一章 引言（Introduction）

### 1.1 研究背景

​	生成模型是人工智能与智能计算领域中的重要研究方向，其核心目标在于**学习真实数据的潜在分布，并从中生成具有统计一致性的新样本**。生成模型不仅在图像、语音与文本生成等感知任务中发挥关键作用，也在数据增强、表示学习、不确定性建模以及科学计算等领域具有重要应用价值。因此，如何设计稳定、高质量且具有可解释性的生成模型，一直是机器学习研究中的核心问题之一。

​	早期具有代表性的生成模型主要包括变分自编码器（Variational Autoencoder, VAE）与生成对抗网络（Generative Adversarial Network, GAN）。VAE 通过显式构建潜变量模型，将数据映射到连续潜在空间，并利用变分推断实现端到端训练，其优点在于理论结构清晰、训练过程稳定，但生成样本往往存在模糊、细节不足的问题。GAN 则通过生成器与判别器之间的对抗博弈进行训练，在图像生成质量上取得了显著突破，但其训练过程高度不稳定，易出现模式崩塌等问题，对超参数和训练技巧较为敏感。上述两类模型在实践中各具优势，但也都面临着稳定性、可控性或理论一致性方面的局限。

​                     <img src="https://www.researchgate.net/publication/356809414/figure/fig1/AS%3A1098577317244930%401638932651307/Example-of-GAN-Architecture.ppm?utm_source=chatgpt.com" alt="Example of GAN Architecture | Download Scientific Diagram" style="zoom:25%;" />                            <img src="https://www.researchgate.net/publication/351917272/figure/fig1/AS%3A1028126347898895%401622135831968/Graphical-representation-of-the-Vanilla-VAE-architecture-The-yellow-orange-and-green.png?utm_source=chatgpt.com" alt="Graphical representation of the Vanilla VAE architecture. The ..." style="zoom:25%;" />

​	从算法思想上看，扩散模型的核心可以概括为“**正向加噪、反向去噪**”：正向过程无需学习参数，仅依赖预先设定的噪声调度策略；反向过程则通过神经网络近似每一步的去噪方向，从而逐步将噪声样本转化为真实数据样本。这种将生成建模问题转化为一系列条件去噪问题的方式，使得扩散模型在理论建模与工程实现之间建立了清晰联系，也为后续算法分析与复现提供了良好的基础。

​		<img src="https://www.researchgate.net/publication/382128283/figure/fig1/AS%3A11431281260181040%401720925618217/The-forward-and-backward-processes-of-the-diffusion-model-The-credit-of-the-used-images.ppm?utm_source=chatgpt.com" alt="https://www.researchgate.net/publication/382128283/figure/fig1/AS%3A11431281260181040%401720925618217/The-forward-and-backward-processes-of-the-diffusion-model-The-credit-of-the-used-images.ppm?utm_source=chatgpt.com" style="zoom:67%;" />

​	正是在这一背景下，DDPM 作为扩散模型中最具代表性的算法之一，为系统理解扩散模型的生成机制与算法设计思想提供了理想切入点。

<img src="https://www.researchgate.net/publication/371956025/figure/fig2/AS%3A11431281250006332%401717736524921/The-schematic-diagram-of-generative-learning-model-includes-VAE-GAN-flow-based-model.tif?utm_source=chatgpt.com" alt="The schematic diagram of generative learning model includes ..." style="zoom:33%;" />

### 1.2 问题定义与研究动机

​	生成建模的核心问题可以表述为：**在仅给定有限样本的情况下，学习一个高维随机变量的真实概率分布，并能够从该分布中高质量地生成新样本**。在概率建模框架下，该问题通常被形式化为对未知数据分布$p_{\text{data}}(x)$的近似建模，其中 $x \in \mathbb{R}^d$ 表示高维观测数据（如图像、语音或信号）。生成模型的目标是构建一个参数化分布 $p_\theta(x)$，使其在统计意义上逼近真实数据分布，即
$$
p_\theta(x) \approx p_{\text{data}}(x)
$$
​	并能够通过从 $p_\theta(x)$ 中采样生成新的、未在训练集中出现的样本。

​	从学习目标上看，生成建模不仅要求模型具备生成能力，即能够产生视觉或语义上合理的新样本，还强调对数据分布结构本身的刻画能力。例如，在图像生成任务中，模型需要捕捉数据在像素空间中的高维相关性；在语音或时序信号建模中，模型还需反映数据在时间维度上的统计规律。因此，生成模型通常被视为一种**显式或隐式的概率密度估计方法**，其研究内容横跨统计建模、随机过程与深度学习等多个领域。

​	本项目关注的问题是如何将 DDPM 原论文中的数学公式完整转化为可运行算法，以及算法在不同深度学习框架下的实现一致性问题。选择 DDPM 作为本项目的研究对象主要出于以下考量：DDPM 的算法结构相对清晰，前向扩散与反向生成过程在数学与实现层面均具有明确划分；另一方面，其理论推导完整，从概率建模到训练目标均有严格的推理基础；同时，DDPM 在实现过程中涉及随机过程建模、神经网络设计与数值算法等多个层面的内容，具有适中的算法设计难度。

### 1.3 项目目标与主要工作

- 理解 DDPM 的数学原理与算法流程
- 基于 PyTorch 完成 DDPM 原始算法的完整复现
- 在 CIFAR-10 数据集上进行实验验证
- 以 OpenAI Improved DDPM 作为拓展方法进行性能对比



## 第二章 DDPM 理论基础与论文算法解析

（Theoretical Background and Algorithm Analysis）

## 2.1 生成建模的概率视角

### 2.1.1 生成模型的统一建模目标

​	生成模型（Generative Models）的核心目标在于**刻画真实数据的生成机制**。设真实数据样本来自未知的数据分布$p_{\text{data}}(x)$, 其中 $x \in \mathbb{R}^d$ 表示高维观测变量（如图像像素、语音信号或其他连续/离散特征）。生成模型通过引入参数化分布 $p_\theta(x)$，试图在统计意义上逼近真实分布，即$p_\theta(x) \approx p_{\text{data}}(x)$。

​	与判别模型侧重于学习条件分布 $p(y\mid x)$ 不同，生成模型直接对数据本身的分布进行建模，其最终目标并非预测标签，而是**从学习到的分布中进行采样**。因此，“生成”在严格意义上可以被理解为：在模型训练完成后，通过从 $p_\theta(x)$ 中采样，得到一组与真实数据在统计特性上一致的样本。

<img src="/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222145532080.png" alt="image-20251222145532080" style="zoom: 25%;" /> <img src="/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222145545726.png" alt="image-20251222145545726" style="zoom:25%;" />

​	生成模型可以根据是否显式建模概率密度，分为**显式密度模型（explicit density models）**与**隐式生成模型（implicit generative models）**两大类。显式密度模型直接给出 $p_\theta(x)$ 或其可计算的下界，例如自回归模型、变分自编码器以及扩散模型等，它们通常具备清晰的概率语义，便于从理论上分析模型行为；而隐式生成模型则不显式给出数据分布的解析形式，而是通过采样过程间接定义生成分布，典型代表为生成对抗网络（GAN）。这两类方法在建模能力、训练稳定性以及理论可解释性方面各具特点，也推动了生成建模方法的不断演进。

### 2.1.2 最大似然估计与 KL 散度

- 所有影响生成模型的共同目标
- 最大化对数似然目标：[\max_\theta \ \mathbb{E}*{x \sim p*{\text{data}}}[\log p_\theta(x)]]与最小化[KL(p_{\text{data}} ,|, p_\theta)]的等价关系
- 生成模型训练的统计意义

---

尽管不同生成模型在结构设计与训练方式上存在显著差异，但从概率建模的角度看，**几乎所有生成模型都围绕着同一个核心目标展开**：使模型分布 $p_\theta(x)$ 在统计意义上尽可能接近真实数据分布 $p_{\text{data}}(x)$。

在显式概率建模框架下，这一目标通常通过**最大似然估计（Maximum Likelihood Estimation, MLE）**来实现。给定从真实数据分布中独立同分布采样得到的数据集，生成模型的训练可以形式化为最大化模型在真实数据上的对数似然期望：
$$
\max_\theta \ \mathbb{E}_{x \sim p_{\text{data}}}[\log p_\theta(x)]
$$
该目标函数具有清晰的统计学含义：它要求模型为真实数据分配尽可能高的概率质量，从而使生成分布在整体上逼近数据分布。

​	进一步地，可以从信息论的角度理解这一优化目标。注意到真实数据分布与模型分布之间的 Kullback–Leibler（KL）散度定义为
$$
KL(p_{\text{data}} \,\|\, p_\theta) = \mathbb{E}_{x \sim p_{\text{data}}}\!\left[\log \frac{p_{\text{data}}(x)}{p_\theta(x)}\right].
$$


由于 $p_{\text{data}}(x)$ 与模型参数 $\theta$ 无关，最小化上述 KL 散度等价于最大化 $\mathbb{E}_{x \sim p_{\text{data}}}[\log p_\theta(x)]$。因此，**最大化对数似然与最小化 $KL(p_{\text{data}} \,\|\, p_\theta)$ 在优化意义上是等价的**。这一等价关系揭示了生成模型训练的本质：通过调整模型参数，使模型分布在信息论意义上尽可能接近真实数据分布。

### 2.2.1 扩散模型的核心思想

​	扩散模型的核心思想在于通过引入一个逐步扰动的随机过程，将复杂的数据分布转化为易于建模的简单分布。具体而言，扩散模型构造了一条由真实数据样本 $x_0$ 出发的随机演化路径
$$
x_0 \rightarrow x_1 \rightarrow \cdots \rightarrow x_T,
$$
在该过程中，噪声被逐步注入数据，使得样本分布随时间演化并逐渐丧失原有结构。当时间步 T 足够大时，数据分布可以近似转化为各向同性的高斯分布。通过这一设计，扩散模型将原本直接建模复杂高维分布的困难问题，转化为在已知噪声机制下学习逆向去噪过程的问题，为后续稳定而可控的生成建模提供了基础。



## 2.5 训练目标推导：从变分下界到 DDPM 损失函数

### 2.5.1 DDPM 的对数似然下界

​	生成建模的基本目标是最大化数据在模型下的对数似然 $\log p_\theta(x_0)$。然而在扩散模型中，$p_\theta(x_0)$ 并不直接以封闭形式给出，而是通过一条从噪声到数据的**反向马尔可夫链**间接定义。为此，DDPM 将生成过程写成对潜变量序列 $x_{1:T}$ 的边缘化：
$$
p_\theta(x_0)=\int p_\theta(x_{0:T})\,dx_{1:T},\qquad  p_\theta(x_{0:T})=p(x_T)\prod_{t=1}^{T}p_\theta(x_{t-1}\mid x_t),
$$
其中先验 $p(x_T)$ 通常取标准高斯 $\mathcal N(0,I)$。与此同时，正向扩散过程 $q(\cdot)$ 作为一个**已知且固定**的马尔可夫链：
$$
q(x_{1:T}\mid x_0)=\prod_{t=1}^{T}q(x_t\mid x_{t-1})
$$
它刻画了从数据 $x_0$ 出发逐步加噪得到 $x_T$ 的机制。由于直接最大化 $\log p_\theta(x_0)$ 仍然困难，DDPM 引入正向链 $q(x_{1:T}\mid x_0)$ 作为变分分布，构造标准的变分下界（ELBO）：
$$
\log p_\theta(x_0) =\log \int q(x_{1:T}\mid x_0)\frac{p_\theta(x_{0:T})}{q(x_{1:T}\mid x_0)}\,dx_{1:T} \ \ge\  \mathbb E_{q(x_{1:T}\mid x_0)}\!\left[\log \frac{p_\theta(x_{0:T})}{q(x_{1:T}\mid x_0)}\right].
$$
因此，最大化对数似然可被替换为最大化一个可计算的下界目标，这也是 DDPM 训练目标推导的起点。



### 2.5.2 变分下界的分解形式

​	将上式中的 $p_\theta(x_{0:T})$ 与 q(x1:T∣x0)q(x_{1:T}\mid x_0)q(x1:T∣x0) 代入，并利用马尔可夫结构，可以将 ELBO 分解为若干项之和:
$$
\mathcal L_{\text{ELBO}}(x_0) = \mathbb E_{q(x_1\mid x_0)}[\log p_\theta(x_0\mid x_1)] -\mathrm{KL}\big(q(x_T\mid x_0)\ \|\ p(x_T)\big) -\sum_{t=2}^{T}\mathbb E_{q(x_t\mid x_0)}\Big[ \mathrm{KL}\big(q(x_{t-1}\mid x_t,x_0)\ \|\ p_\theta(x_{t-1}\mid x_t)\big) \Big].
$$
这一分解具有清晰的概率含义：

- **终止项（prior matching term）**: $\mathrm{KL}\big(q(x_T\mid x_0)\ \|\ p(x_T)\big)$

  衡量正向扩散到末端的分布是否与预设先验 $p(x_T)=\mathcal N(0,I)$对齐。直观上，它鼓励“扩散足够彻底”，使得 $x_T$ 近似标准高斯。

- **中间多步 KL 项（denoising matching term）**: $\sum_{t=2}^{T}\mathbb E_{q(x_t\mid x_0)}\Big[ \mathrm{KL}\big(q(x_{t-1}\mid x_t,x_0)\ \|\ p_\theta(x_{t-1}\mid x_t)\big) \Big]$

  逐步约束模型反向转移 pθ(xt−1∣xt)p_\theta(x_{t-1}\mid x_t)pθ(xt−1∣xt) 去逼近真实的后验反向分布 q(xt−1∣xt,x0)q(x_{t-1}\mid x_t,x_0)q(xt−1∣xt,x0)。这部分是“学会去噪”的核心。

- **重建项（reconstruction term）**:$\mathbb E_{q(x_1\mid x_0)}[\log p_\theta(x_0\mid x_1)]$

  描述最后一步从 $x_1$ 复原到 $x_0$ 的似然质量，可理解为对生成样本精细度的直接约束。

​	由此可见，DDPM 的训练本质上是在最大化 ELBO：一方面使末端噪声与先验匹配，另一方面在每个时间步都让反向链逼近真实的去噪后验，从而保证整个生成链条在概率意义上成立。



## 2.3 正向扩散过程建模（Forward Diffusion Process）

### 2.3.1 正向扩散过程的定义

​	在 DDPM 中，正向扩散过程被建模为一个**固定的马尔可夫随机过程**，其作用是将原始数据样本逐步转化为噪声样本。

![image-20251222150852107](/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222150852107.png)

​	马尔可夫假设意味着当前状态 $x_t$ 仅依赖于前一时刻的状态 $x_{t-1}$，与更早的历史状态无关。在该假设下，正向扩散过程可以通过一系列条件高斯分布来刻画，其形式定义为
$$
q(x_t \mid x_{t-1}) = \mathcal{N}\!\left(\sqrt{1-\beta_t}\,x_{t-1},\ \beta_t I\right),
$$
其中 $\beta_t \in (0,1)$ 表示第 t 个时间步注入噪声的强度。该定义表明，在每一步扩散过程中，样本在保留部分原有信息的同时，被叠加了独立的高斯噪声，从而逐步偏离原始数据分布。从建模角度看，正向扩散过程是**人为设定且无需学习的**，其参数完全由预定义的噪声调度策略决定。这一特性使得正向过程在训练与采样阶段均可被精确控制，为后续反向生成过程的学习提供了稳定的参考分布。

### 2.3.2 噪声调度参数与物理意义

​	为了便于分析与实现，DDPM 中通常引入一组与 $\beta_t$ 相关的辅助参数。首先定义$\alpha_t = 1 - \beta_t$,并进一步定义其累积乘积$\bar{\alpha}_t = \prod_{s=1}^{t} \alpha_s$.其中，$\alpha_t$ 描述了单步扩散中保留原有信号的比例，而 $\bar{\alpha}_t$ 则刻画了从初始时刻 0 到时间步 t 为止，原始数据 $x_0$ 在样本中所占的整体权重。

​	从直观上看，随着时间步 t 的增加，$\beta_t$ 所引入的噪声不断累积，使得 $\bar{\alpha}_t$ 逐渐减小，样本中来自 $x_0$ 的信息逐步被噪声淹没。当 ttt 足够大时，样本几乎完全由高斯噪声主导，其分布可以近似为标准正态分布。这一“逐步遗忘原始结构”的过程，正是扩散模型得名的物理直觉来源。

### 2.3.3 正向过程的封闭形式

​	基于上述参数定义，可以进一步推导正向扩散过程相对于初始数据 $x_0$ 的**封闭形式表达**。利用高斯分布在逐步线性变换下的封闭性，可以得到：
$$
q(x_t \mid x_0) = \mathcal{N}\!\left(\sqrt{\bar{\alpha}_t}\,x_0,\ (1-\bar{\alpha}_t)I\right).
$$
​	这一结果表明，在任意时间步 t，样本 $x_t$ 都可以被视为由原始数据 $x_0$ 与独立高斯噪声按比例线性叠加而成。进一步地，上式可以被重写为一步采样的形式：
$$
x_t = \sqrt{\bar{\alpha}_t}\,x_0 + \sqrt{1-\bar{\alpha}_t}\,\epsilon,\quad \epsilon \sim \mathcal{N}(0,I).
$$
![image-20251222151404711](/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222151404711.png)

------

## 2.4 反向生成过程与参数化建模（Reverse Process）

本节目标是将第 2.2 节中 ELBO 的中间项转化为一个**可训练的神经网络(Denoised Network)损失函数**。

### 2.4.1 反向生成过程

​	在扩散模型中，正向扩散过程通过逐步注入噪声将数据分布转化为近似高斯分布；与之对应，生成过程的核心任务在于**学习一个反向的去噪过程**，使模型能够从噪声样本逐步恢复出真实数据。为使反向生成过程在工程上可实现，DDPM 对反向条件分布作出合理的参数化假设，即将其建模为一个高斯分布：$p_\theta(x_{t-1}\mid x_t)$。

![The DDPM diagram. The upper row depicts the forward diffusion ...](https://www.researchgate.net/publication/370234882/figure/fig1/AS%3A11431281212194568%401702559206374/The-DDPM-diagram-The-upper-row-depicts-the-forward-diffusion-process-the-lower-row.tif?utm_source=chatgpt.com)

​	由于正向扩散为高斯马尔可夫过程，可证明理论反向分布亦为高斯，因此对模型分布作如下假设：
$$
p_\theta(x_{t-1}\mid x_t) = \mathcal N\!\big(\mu_\theta(x_t,t),\ \Sigma_\theta(x_t,t)\big).
$$
在DDPM原文中采用固定方差$\Sigma_\theta(x_t,t)=\sigma_t^2 I$，仅学习均值函数 $\mu_\theta(x_t,t)$

### 2.5.4 噪声预测网络

![image-20251222161847728](/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222161847728.png)

​	DDPM 引入一个**共享参数的去噪神经网络（Denoiser Network）**，在所有时间步上复用，用以刻画反向生成过程的动态行为。该网络以当前带噪样本与时间步为输入
$$
(x_t,\ t)\ \longmapsto\ \text{Denoiser}(x_t,t) = \varepsilon_{\theta}(x_t,x)
$$
并通过输出对噪声或等价参数的预测，间接确定反向高斯分布的均值项。训练目标是用预测噪声近似前向扩散过程中的实际噪声。
$$
\varepsilon_{\theta}(x_t,x) \approx \varepsilon
$$


​	在下一小节，我们将说明该预测在数学上等价于对反向高斯分布 $p_\theta(x_{t-1}\mid x_t)$均值参数的建模，从而将最大化对数似然下界的问题转化为稳定的回归学习任务。

### 2.4.3 反向生成过程的训练目标

​	由 ELBO 分解可知，DDPM 的学习目标在于对每一时间步 t 最小化：
$$
\mathrm{KL}\big(q(x_{t-1}\mid x_t,x_0)\ \|\ p_\theta(x_{t-1}\mid x_t)\big).
$$
其中：理论反向分布$q(x_{t-1}\mid x_t,x_0)$是真实的一步去噪后验，因为正向扩散是线性高斯马尔可夫链，利用贝叶斯公式可计算出它满足的高斯分布
$$
q(x_{t-1}|x_t, x_0) = \frac{q(x_t|x_{t-1})q(x_{t-1}|x_0)}{q(x_t|x_0)}，\\q(x_{t-1}\mid x_t,x_0)=\mathcal N\!\big(\tilde\mu_t(x_t,x_0),\ \tilde\beta_t I\big).\\
\boxed{ q(x_{t-1}\mid x_t,x_0) = \mathcal N\!\left( x_{t-1}; \ \frac{\sqrt{\bar\alpha_{t-1}}\beta_t}{1-\bar\alpha_t}\,x_0 +\frac{\sqrt{\alpha_t}(1-\bar\alpha_{t-1})}{1-\bar\alpha_t}\,x_t, \ \frac{1-\bar\alpha_{t-1}}{1-\bar\alpha_t}\beta_t\, I \right) }
$$
可以看出， q的分布依赖 $x_0$，生成阶段不可用；模型反向分布$p_{\theta}(x_{t-1}\mid x_t)$是唯一需要学习的对象。使$p_{\theta}$的方差与q的方差一致，最小化KL散度等价于最小化均值之间的距离。

![image-20251222160851868](/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222160851868.png)

在前向扩散加噪中，$x_t$与$x_0$的关系是确定的。
$$
x_t = \sqrt { \overline{\alpha}_t}x_0+\sqrt{1-\overline{\alpha}_t}\varepsilon
$$
 将上式代入14中的$q(x_{t-1}|x_t,x_0)$的均值表达式，可以得到
$$
\mu_q = \frac{1}{\sqrt{\alpha_t}}(x_t-\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}\varepsilon)
$$
$\mu_q$仅仅与$x_t$, $\varepsilon$有关，而$\varepsilon$是我们在Denoised Network中预测的噪声。因此DDPM的denoiser表面上是在去噪，实际上是在用噪声预测的方式间接学习反向高斯分布$p_{\theta}(x_{t-1}|x_{t})$的参数，从而最大化数据的对数似然下界。

------



## 2.6 DDPM 的训练与采样算法解析

DDPM 的核心实现可以概括为两套算法：

- **训练（Algorithm 1）**：随机选时间步 t，把真实样本 $x_0$ 加噪得到 $x_t$，训练Denoiser网络预测噪声 $\varepsilon$；
- **采样（Algorithm 2）**：从纯噪声 $x_T\sim \mathcal N(0,I)$ 出发，按 $t=T,T-1,\dots,1$ 逐步采样 $x_{t-1}\sim p_\theta(x_{t-1}\mid x_t)$。

### 2.6.1 训练算法（Algorithm 1）

<img src="/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222163524537.png" alt="image-20251222163524537" style="zoom:50%;" />

- 随机采样时间步 ( t )
- 构造带噪样本 ( $x_t$ )
- 噪声回归损失与梯度更新

<img src="/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222163834612.png" alt="image-20251222163834612" style="zoom:33%;" />

### 2.6.2 采样算法（Algorithm 2）

<img src="/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222163536895.png" alt="image-20251222163536895" style="zoom:50%;" />

在生成阶段，DDPM 采用反向扩散过程进行采样。该过程从各向同性高斯分布中初始化样本 $x_T \sim \mathcal{N}(0,I)$，并在时间步$t = T, T-1, \ldots, 1$ 上逐步执行反向更新。对于每一时间步，当前带噪样本 $x_t$ 与对应的时间编码 ttt 被输入去噪网络，网络输出对正向扩散噪声的估计 $\varepsilon_\theta(x_t,t)$。采用第t步的带噪样本$x_t$减去Denoiser预测出的噪声乘上权重系数$\frac{1-\alpha_t}{\sqrt{1-\overline{\alpha}_t}}$，得到比$x_t$更加纯净的带噪图像$x_{t-1}$



![image-20251222163914919](/Users/yufei/course/算法设计与智能计算/project2/DDPM/Report/assets/image-20251222163914919.png)



## 第三章 算法设计：DDPM 的 PyTorch 复现

（Algorithm Design and Re-implementation）

> **本章为项目核心章节**

### 3.1 算法复现任务定义

- 输入、输出与问题形式化描述
- 复现目标：Ho et al. (2020) 原始 DDPM 算法
- 不直接调用现成 DDPM 库的说明

### 3.2 前向扩散算法的实现

- 噪声调度策略的实现方式
- q(xₜ | x₀) 的 PyTorch 张量化实现
- 一步采样技巧的工程实现

### 3.3 反向去噪与采样算法设计

- ε_θ 网络的训练目标
- 反向采样更新公式的数值实现
- 采样过程中随机性的处理方式

### 3.4 神经网络结构与时间嵌入设计

- U-Net 网络结构选择理由
- 时间步 t 的嵌入方式
- PyTorch 实现中的关键工程细节

### 3.5 算法伪代码与整体流程总结

- 训练阶段伪代码
- 采样阶段伪代码

------

## 第四章 算法复杂度与性能分析

（Complexity and Performance Analysis）

### 4.1 时间复杂度分析

- 训练阶段复杂度
- 采样阶段复杂度（与采样步数 T 的关系）

### 4.2 空间复杂度分析

- 网络参数规模
- 中间特征图与显存开销

### 4.3 原始 DDPM 与改进方法的复杂度对比（定性）

- 训练稳定性
- 采样效率
- 工程复杂度差异

------

## 第五章 实验设计与结果分析

（Experiments and Results）

### 5.1 实验环境与数据集

- CIFAR-10 数据集介绍
- 硬件与软件环境说明

### 5.2 Baseline 实验：PyTorch 复现的 DDPM（核心）

- 实验目的：验证算法复现的正确性
- 训练过程与损失变化
- 生成样本可视化结果
- 生成效果的定性分析

### 5.3 拓展实验：OpenAI Improved DDPM

- 引入 Improved DDPM 的动机
- 改进点简要说明（如噪声建模、采样方式）
- 实验结果展示

### 5.4 Baseline 与 Improved DDPM 的对比分析

- 生成样本质量对比
- 训练稳定性对比
- 算法改进带来的性能变化分析

------

## 第六章 讨论：算法复现中的理论与工程问题

（Discussion）

### 6.1 理论公式与工程实现的差异

- 数值稳定性问题
- 参数设置对结果的影响

### 6.2 框架差异带来的实现影响

- PyTorch 与 TensorFlow 的实现差异
- 自动求导与张量操作的不同处理方式

### 6.3 项目局限性与改进方向

- 采样速度问题
- 可能的拓展方向（DDIM、Score-based 方法）

------

## 第七章 小组分工与贡献说明

（Teamwork and Contribution）

### 7.1 小组成员信息

- 姓名
- 学号

### 7.2 分工情况说明

- 理论推导
- 算法复现
- 实验分析
- 报告与展示

### 7.3 贡献比例说明

- 明确贡献比例
- 成绩计算方式说明

------

## 第八章 总结与展望（Conclusion）

- 本项目完成情况总结
- 主要收获与经验
- 后续可深入研究的方向

------

## 参考文献（References）

- DDPM 原论文（Ho et al., 2020）
- OpenAI Improved DDPM 相关论文与代码
- 其他参考资料（明确标注来源）
